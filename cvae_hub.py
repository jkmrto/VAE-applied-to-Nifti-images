import os

import tensorflow as tf

from lib import session_helper
from lib.aux_functionalities.functions import get_batch_from_samples_unsupervised_3d
from lib.aux_functionalities.os_aux import create_directories
from lib.test_over_segmenting_regions import load_regions_segmented
from settings import path_to_project


class cvae_3d():
    """
    Juan Carlos Martinez de la Torre
    """

    RESTORE_KEY = "restore"

    def __init__(self, architecture=None, hyperparams=None, meta_graph=None,
                 path_to_session=None, test_bool=False):

        """(Re)build a symmetric VAE model with given:

            * architecture (list of nodes per encoder layer); e.g.
               [1000, 500, 250, 10] specifies a VAE with 1000-D inputs, 10-D latents,
               & end-to-end architecture [1000, 500, 250, 10, 250, 500, 1000]

            * hyperparameters (optional dictionary of updates to `DEFAULTS`)
        """

        self.session = tf.Session()
        self.hyper_params = hyperparams
        self.path_session_folder = path_to_session

        self.n_hidden = 500
        self.n_z = 1000
        self.batchsize = 100
        self.input_shape = [34, 42, 41]
        self.filter_per_layer = [8, 16]
        self.stride = 2
        self.learning_rate = 0.00001
        self.kernel_size = 2
        self.activation = tf.nn.sigmoid


        # summaryWritter under testing

        logs_path = os.path.join(path_to_project, "cvae_logs")

        if not meta_graph:  # new model
            self.architecture = architecture

            if test_bool:
                print("Hyperparamers indicated: " + str(self.hyper_params))

            # path_to_session should be indicated if we want to create data
            # associated to the session such as the logs, and metagraphs
            # generated by sensor flow. It it is just a test session, in order
            # to test a feature, it is not necessary to indicate the path
            if None is not self.path_session_folder:
                self.init_session_folders()

            # build graph
            handles = self._build_graph()
            for handle in handles:
                tf.add_to_collection(cvae_3d.RESTORE_KEY, handle)
            self.session.run(tf.global_variables_initializer())

        else:  # restore saved model
            tf.train.import_meta_graph(meta_graph + ".meta").restore(
                self.session, meta_graph)
            handles = self.session.graph.get_collection_ref(cvae_3d.RESTORE_KEY)

        self.x_in, self.z_mean, self.z_stddev, self.images_out, self.cost,\
            self.global_step, self.generation_loss, self.latent_loss= handles[0:8]


        self.writer = tf.summary.FileWriter(logs_path, graph=self.session.graph)

    def init_session_folders(self):
        """
        This method will create inside the "out" folder a folder with the datetime
        of the execution of the neural net and with, with 3 folders inside it
        :return:
        """
        self.path_to_images = os.path.join(self.path_session_folder, "images")
        self.path_to_logs = os.path.join(self.path_session_folder, "logs")
        self.path_to_meta = os.path.join(self.path_session_folder, "meta")
        self.path_to_grad_desc_error = os.path.join(self.path_to_logs,
                                                    "DescGradError")

        create_directories([self.path_session_folder, self.path_to_images,
                            self.path_to_logs, self.path_to_meta])

    def _build_graph(self):
        print("The methoud _build_graph is not implemented")
        pass

    def train(self, x_in, bool_save_meta=False, max_iter=1000):

        n_samples = x_in.shape[0]
        # train
        if bool_save_meta:
            saver = tf.train.Saver(max_to_keep=2)

        i = 0
        while True:

            batch = get_batch_from_samples_unsupervised_3d(
                x_in, 16)

            feed_dict = {self.x_in: batch}
            fetches = [self.cost, self.generation_loss, self.latent_loss]

            [cost, generation_loss, latent_loss] =  \
                self.session.run(fetches, feed_dict=feed_dict)

            # dumb hack to print cost every epoch
            if i % 20 == 0:
                print("iter {0}, error {1}, GEN: {2}, LATENT {3}".format(
                    i, cost, generation_loss, latent_loss))

            if bool_save_meta:
                saver.save(self.session, os.getcwd() + "/training/train",
                            global_step=i)
            i = i +1

            if i >= max_iter:
                self.writer.close()
                break


#regions_used = "three"
#list_regions = session_helper.select_regions_to_evaluate(regions_used)
#region = 3
#region_segmented = load_regions_segmented(list_regions)[3]
#print(region_segmented.shape)
#cvae = cvae_3d()
#print("training")
#cvae.train(x_in=region_segmented)
